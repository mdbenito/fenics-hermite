{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete gradient operators\n",
    "\n",
    "This notebook collects my progress towards the definition of the operator\n",
    "\n",
    "$$\\nabla_h:W_h \\rightarrow \\Theta_h$$\n",
    "\n",
    "as defined in (Bartels, 2015) ยง8.2.1.\n",
    "\n",
    "## First goal: derivative of a piecewise linear function\n",
    "\n",
    "Let $u \\in V$, where $V$ is a CG1 finite element space. Then $u'$ is piecewise constant (i.e. it is in DG0). We want to compute the matrix $D_h$ for \n",
    "\n",
    "$$\\nabla_h:V \\rightarrow V'$$\n",
    "\n",
    "such that $(D_h u)_j$ = $(\\nabla_h u)_j = u_j'$. Note that we are using the same  notation for a function $u$ and for the vector of its coefficients in the basis of the space it lives on.\n",
    "\n",
    "Since $u'$ is not in the same space as $u$, in FEniCS we need to `project()` it onto $V'$, which is costly. What we are doing is to manually compute the derivative. This should be easy since\n",
    "\n",
    "$$ u = \\sum_i \\alpha_i \\phi_i $$\n",
    "\n",
    "where $V = \\text{span} \\{\\phi_i\\} $, hence:\n",
    "\n",
    "$$ u' = \\sum_i \\alpha_i \\phi_i'. $$\n",
    "\n",
    "We can use `evaluate_basis_derivatives()` for this purpose, assembling the transformation matrix by hand.\n",
    "\n",
    "We define $V' = \\text{span} \\{\\phi_i'\\}$, a DG0 space, and compute the linear mapping of dofs from $V$ to $V'$, then apply this mapping to the coefficients of $u$ and construct $u' \\in V'$ with these coefficients.\n",
    "\n",
    "For simplicity, consider first a 1D mesh. Let $i \\in \\{0,1,...,M\\}$ be an index over the cells of the mesh such that:\n",
    "\n",
    "* $u_i,u_{i+1}$ are the coefficients for the dofs in $V$ over cell $i$\n",
    "* $u_i'$ is the coefficient for the only dof in $V'$ (the constant 1) over cell $i$\n",
    "\n",
    "Then we only need to compute $\\phi_i'$ for each $i$ to obtain the new vector of coefficients $(u_i')_{i=0}^{N_{V'}}$:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{ccccc}\n",
    "  \\phi_0' & \\phi_1' &  &  & \\\\\n",
    "  & \\phi_1' & \\phi_2' &  & \\\\\n",
    "  &  & \\phi_2' & \\phi_3' & \\\\\n",
    "  &  &  & \\phi_3' & \\phi_4'\n",
    "\\end{array}\\right)  \\left(\\begin{array}{c}\n",
    "  u_0\\\\\n",
    "  u_1\\\\\n",
    "  u_2\\\\\n",
    "  u_3\\\\\n",
    "  u_4\n",
    "\\end{array}\\right) = \\left(\\begin{array}{c}\n",
    "  u_0'\\\\\n",
    "  u_1'\\\\\n",
    "  u_2'\\\\\n",
    "  u_3'\n",
    "\\end{array}\\right).$$\n",
    "\n",
    "Note that in this particular instance and with the assumptions made, we obtain a band matrix and computing $u'$ is actually a matter of computing the dot product of a \"subset\" of the vector of constants $(\\phi_0', ..., \\phi_{N_{V'}}')$ with $u$.\n",
    "\n",
    "However in other situations, e.g. in higher dimensions, the ordering of the nodes won't be as convenient. We proceed then more generally as follows: Let $i$ run over all cell indices and let $\\iota_i$ be the local-to-global mappings for $V$ and $\\iota_i'$ for $V'$. Initialise the matrix $M$ of the discrete gradient to zero. At each step of the construction of $M$ we edit row $r = \\iota_i'(0)$, i.e. the row whose product by $(u)_j$ will return the coefficient for the dof in $V'$ corresponding to cell $i$.\n",
    "\n",
    "Now, for every vertex $v_j,\\ j \\in \\{0,...,d\\}$ in cell $i$ compute the value of the derivative of the global dof $\\phi_{\\iota_r(j)}$ and set\n",
    "\n",
    "$$M_{r j} = \\phi_{\\iota_r(j)},\\ j \\in \\{0,...,d\\}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dolfin import *\n",
    "from petsc4py import PETSc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "\n",
    "# instruct FFC to produce the code for evaluate_basis_derivatives()\n",
    "parameters[\"form_compiler\"][\"no-evaluate_basis_derivatives\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_discrete_gradient_dense(V, Vp):\n",
    "    \"\"\" Build dense matrix of the discrete gradient operator between V and Vp.\n",
    "    Arguments:\n",
    "        V: Source FunctionSpace of type CG1.\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "    Returns:\n",
    "        Dh: np.ndarray of shape (Vp.dim(), V.dim()) such that for u in V,\n",
    "              np.dot(Dh, u.vector().array())\n",
    "            yields the vector of coefficients of the discrete gradient of u\n",
    "            in Vp.\n",
    "    \"\"\"\n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'CG1', \"Need a CG1 source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x DG0' % gdim or\\\n",
    "           Vp.ufl_element().shortstr()[:3] == 'DG0',\\\n",
    "           \"I need a DG0 (Vector)FunctionSpace of the right number of components\"\n",
    "    assert Vp.mesh().num_cells() * gdim == Vp.dim(),\\\n",
    "           \"FunctionSpace dimensions don't match.\"\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Meshes don't match\"\n",
    "\n",
    "    dm = V.dofmap()\n",
    "    dmp = Vp.dofmap()\n",
    "    e = V.element()\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "    coordsp = Vp.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "\n",
    "    Dh = np.zeros((Vp.dim(), V.dim()))\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "    vals = np.zeros(dm.num_element_dofs(0)*gdim)\n",
    "    for cell_id in range(Vp.mesh().num_cells()):\n",
    "        rows = dmp.cell_dofs(cell_id)\n",
    "        columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[columns,:]\n",
    "        point = dof_coords[0] # Any point in the (closure of the) cell will do.\n",
    "        e.evaluate_basis_derivatives_all(1, vals, point, dof_coords, 1)\n",
    "        #print(\"rows=%s, columns=%s, point=%s, dof_coords=%s, vals=%s\" %\n",
    "        #     (rows, columns, point, dof_coords, vals.round(2)))\n",
    "        # Reshape [df_1/dx, df_1/dy, df_2/dx, df_2/dy, ...] into\n",
    "        # [[df_1/dx, df_2/dx, ...],[df_1/dy, df_2/dy, ...]] :\n",
    "        #Dh[FIXTHIS:\"rows, columns\"] = vals.reshape((-1, gdim)).T.copy()\n",
    "        for offset in range(gdim):\n",
    "            Dh[rows[offset], columns] = vals[offset::gdim].copy()\n",
    "\n",
    "    return Dh\n",
    "\n",
    "def compute_discrete_gradient_dense(V, Vp, u):\n",
    "    \"\"\"  \"\"\"\n",
    "    Dh = build_discrete_gradient_dense(V, Vp)\n",
    "    up = Function(Vp)\n",
    "    up.vector().set_local(np.dot(Dh, u.vector().array()))\n",
    "    up.vector().apply('insert')\n",
    "\n",
    "    return up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To thest the previous code we start with an expression whose derivative we can compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEFT, RIGHT = -pi, 2*pi\n",
    "mesh = IntervalMesh(100, LEFT, RIGHT)\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "Vp = FunctionSpace(mesh, \"DG\", 0)\n",
    "\n",
    "#x = SpatialCoordinate(mesh)\n",
    "#f = sin(x[0])\n",
    "#u = project(f, V)\n",
    "u = interpolate(Expression(\"sin(x[0])\", element=V.ufl_element()), V)\n",
    "dg_u = compute_discrete_gradient_dense(V, Vp, u)\n",
    "\n",
    "# Test\n",
    "#up = project(f.dx(0), Vp)\n",
    "up = interpolate(Expression(\"cos(x[0])\", element=Vp.ufl_element()), Vp)\n",
    "print(\"Error: %e\" % (dg_u.vector() - up.vector()).norm('linf'))\n",
    "plot(up)\n",
    "plot(dg_u)\n",
    "_ = pl.xlim((LEFT*1.1, RIGHT*1.1)), pl.ylim((-1.1,1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A detour using projections\n",
    "\n",
    "The following method computes the solution via a projection onto DG0 but instead of letting FEniCS assemble the mass matrix, we make use of the fact that it is diagonal with entries given by the cell volume. Then it is trivial to invert it and multiply the rhs of the projection problem. The idea and code are taken from [this question on FEniCS Q&A](https://fenicsproject.org/qa/12634/gradient-of-a-cg-order-one-element?show=12646#a12646)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dolfin import *\n",
    "import numpy as np\n",
    "\n",
    "mesh = UnitCubeMesh(30, 30, 30)\n",
    "W = FunctionSpace(mesh, 'CG', 1)\n",
    "Q = VectorFunctionSpace(mesh, 'DG', 0)\n",
    "p, q = TrialFunction(Q), TestFunction(Q)\n",
    "\n",
    "f = Function(W)\n",
    "f_vec = f.vector()\n",
    "f_vec.set_local(np.random.rand(f_vec.local_size()))\n",
    "f_vec.apply('insert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the gradient via a projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "L = inner(grad(f), q)*dx\n",
    "M = assemble(inner(p, q)*dx)\n",
    "b = assemble(L)\n",
    "\n",
    "grad_f0 = Function(Q)\n",
    "x0 = grad_f0.vector()\n",
    "_ = solve(M, x0, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiroK's idea (which amounts to building our matrix $D_h$) in the forum is to \"assemble the action of Minv onto the rhs - no mass matrix needed\". The improvement in speed is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MinvL = (1/CellVolume(Q.mesh()))*inner(grad(f), q)*dx\n",
    "x = assemble(MinvL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad_f = Function(Q, x)\n",
    "print(\"Error: %e\" % (x - x0).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the first approach we compute $M$, then solve $M x = b$ and in the second we compute $M^{-1}$ directly to obtain $x = M^{-1} b$.\n",
    "\n",
    "### How does the assembly of the projection problem work?\n",
    "\n",
    "Write the compiled form to a file and check `dgrad_cell_integral_0_otherwise::tabulate_tensor()` for the implementation. Recall that `u.dx()` in the form is the derivative of a terminal node in UFL so it is the responsibility of FFC to fill that. How does this work again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ffc\n",
    "with open(\"/tmp/dgrad.h\", \"wt\") as fd:\n",
    "    out = ffc.compile_form(MinvL, prefix=\"dgrad\")\n",
    "    fd.write(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And back\n",
    "\n",
    "We can use our function instead. This will be much slower and also use a lot of memory because of the dense matrix we are using. The error is different, though. **Could this be significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dg_f = compute_discrete_gradient_dense(W, Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (dg_f.vector() - grad_f0.vector()).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use PETSc for the discrete gradient operator\n",
    "\n",
    "We achieve a back-of-the-napkin speed improvement of up to 50 times wrt. the implementation with dense matrices and stay in the same range of running times than the method using `project()`. We can only test for manageable matrix sizes but we can now of course manage bigger matrices. The speedup depends greatly on the size of the matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_discrete_gradient(V, Vp):\n",
    "    \"\"\" Build sparse PETSc matrix of the discrete gradient operator\n",
    "    between V and Vp.\n",
    "    Arguments:\n",
    "        V: Source FunctionSpace of type CG1.\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "    Returns:\n",
    "        Dh: PETSc sparse matrix such that for u in V,\n",
    "              Dh * u.vector().array()\n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"\n",
    "    from petsc4py import PETSc\n",
    "    \n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'CG1', \"Need a CG1 source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x DG0' % gdim or\\\n",
    "           Vp.ufl_element().shortstr()[:3] == 'DG0',\\\n",
    "           \"I need a DG0 (Vector)FunctionSpace of the right number of components\"\n",
    "    assert Vp.mesh().num_cells() * gdim == Vp.dim(),\\\n",
    "           \"FunctionSpace dimensions don't match\"\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Number of cells in the meshes don't match\"\n",
    "\n",
    "    dm = V.dofmap()\n",
    "    dmp = Vp.dofmap()\n",
    "    e = V.element()\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "    coordsp = Vp.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "\n",
    "    Dh = PETSc.Mat()\n",
    "    Dh.create(PETSc.COMM_WORLD)  # What is this?\n",
    "    Dh.setSizes([Vp.dim(), V.dim()])\n",
    "    Dh.setType(\"aij\")\n",
    "    Dh.setUp()\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "    vals = np.zeros(dm.num_element_dofs(0)*gdim)\n",
    "    # TODO: check this for parallel operation...\n",
    "    istart, iend = Dh.getOwnershipRange()\n",
    "    print (\"This process owns the range %d - %d\" % (istart, iend))\n",
    "    for cell_id in range(Vp.mesh().num_cells()):\n",
    "        rows = dmp.cell_dofs(cell_id)\n",
    "        rows = rows[(rows>=istart) & (rows < iend)]\n",
    "        columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[columns,:]\n",
    "        point = dof_coords[0] # Any point in the (closure of the) cell will do.\n",
    "        e.evaluate_basis_derivatives_all(1, vals, point, dof_coords, 1)\n",
    "        #print(\"rows=%s, columns=%s, point=%s, dof_coords=%s, vals=%s\" %\n",
    "        #     (rows, columns, point, dof_coords, vals.round(2)))\n",
    "        # Reshape [df_1/dx, df_1/dy, df_2/dx, df_2/dy, ...] into\n",
    "        # [[df_1/dx, df_2/dx, ...],[df_1/dy, df_2/dy, ...]] :\n",
    "        # NOTE: the copy() is necessary!\n",
    "        Dh.setValues(rows, columns, vals.reshape((-1, gdim)).T.copy())\n",
    "    Dh.assemble()\n",
    "    return Dh\n",
    "\n",
    "def compute_discrete_gradient(V, Vp, u):\n",
    "    \"\"\"  \"\"\"\n",
    "    Dh = build_discrete_gradient(V, Vp)\n",
    "    du = Function(Vp)\n",
    "    petsc_u = as_backend_type(u.vector()).vec()\n",
    "    petsc_du = as_backend_type(du.vector()).vec()\n",
    "    \n",
    "    Dh.mult(petsc_u, petsc_du)\n",
    "    du.vector().apply('insert')\n",
    "\n",
    "    return du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LEFT, RIGHT = -pi, 2*pi\n",
    "mesh = IntervalMesh(1000, LEFT, RIGHT)\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "Vp = FunctionSpace(mesh, \"DG\", 0)\n",
    "\n",
    "#Dh = build_discrete_gradient(V, Vp)\n",
    "u = interpolate(Expression(\"sin(x[0])\", degree=1), V)\n",
    "du0 = interpolate(Expression(\"cos(x[0])\", degree=0), Vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "du = compute_discrete_gradient(V, Vp, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (du.vector() - du0.vector()).norm('linf'))\n",
    "_ = plot(du)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is faster than the solution with dense matrices but obviously still much slower (a little below 40 times) than building $M^{-1}$ directly because of the hideously slow python loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dg_fs = compute_discrete_gradient(W, Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (dg_f.vector() - dg_fs.vector()).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A rewrite in C++?\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
