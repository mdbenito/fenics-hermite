{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete gradient operators\n",
    "\n",
    "This notebook collects my progress towards the definition of the operator\n",
    "\n",
    "$$\\nabla_h:W_h \\rightarrow \\Theta_h$$\n",
    "\n",
    "as defined in (Bartels, 2015) ยง8.2.1. We proceed as follows:\n",
    "\n",
    "1. Computation of (global) gradient for CG1 functions, i.e. as an operator from CG1 into CG0.\n",
    "2. Computation of (global) gradient for DKT functions, i.e. as an operator from DKT into CG2^2.\n",
    "3. Implementation in the assembly process. (*to do*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The usual boilerplate...\n",
    "\n",
    "from itertools import chain\n",
    "from dolfin import *\n",
    "from petsc4py import PETSc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=150)\n",
    "\n",
    "def __nbinit__():\n",
    "    global __all__\n",
    "    __all__ = ['compute_discrete_gradient_dense', \n",
    "               'compute_discrete_gradient',\n",
    "               'compute_dkt_gradient']\n",
    "    global parameters\n",
    "    # instruct FFC to produce the code for evaluate_basis_derivatives()\n",
    "    parameters[\"form_compiler\"][\"no-evaluate_basis_derivatives\"] = False\n",
    "\n",
    "__nbinit__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient of a piecewise linear function\n",
    "\n",
    "** To do:** A rewrite in C++?\n",
    "\n",
    "Let $u \\in V$, where $V$ is a CG1 finite element space. Then $u'$ is piecewise constant (i.e. it is in DG0). We want to compute the matrix $D_h$ for \n",
    "\n",
    "$$\\nabla_h:V \\rightarrow V'$$\n",
    "\n",
    "such that the $j$-th coefficient of $u'$ in $V'$, $(\\nabla u)_j = (\\nabla_h u)_j =: u_j'$. Note that we are using the same  notation for a function $u$ and for the vector of its coefficients in the basis of the space it lives on.\n",
    "\n",
    "Since $u'$ is not in the same space as $u$, in FEniCS we need to `project()` it onto $V$, which is costly. What we are doing is to manually compute the derivative. This should be easy since\n",
    "\n",
    "$$ u = \\sum_i u_i \\phi_i $$\n",
    "\n",
    "where $V = \\text{span} \\{\\phi_i\\} $, and therefore, by linearity:\n",
    "\n",
    "$$ u' = \\sum_i u_i \\phi_i'. $$\n",
    "\n",
    "We could use `evaluate_basis_derivatives()` to evaluate the $\\phi_i'$ and then we would be able to evaluate $u'$. However, we are interested in obtaining new coefficients $u_i'$ such that\n",
    "\n",
    "$$ u' = \\sum_i u_i \\psi_i', $$\n",
    "\n",
    "where\n",
    "\n",
    "assembling the transformation matrix by hand.\n",
    "\n",
    "We define $V' = \\text{span} \\{\\phi_i'\\}$, a DG0 space, and compute the linear mapping of dofs from $V$ to $V'$, then apply this mapping to the coefficients of $u$ and construct $u' \\in V'$ with these coefficients.\n",
    "\n",
    "For simplicity, consider first a 1D mesh. Let $i \\in \\{0,1,...,M\\}$ be an index over the cells of the mesh such that:\n",
    "\n",
    "* $u_i,u_{i+1}$ are the coefficients for the dofs in $V$ over cell $i$\n",
    "* $u_i'$ is the coefficient for the only dof in $V'$ (the constant 1) over cell $i$\n",
    "\n",
    "Then we only need to compute $\\phi_i'$ for each $i$ to obtain the new vector of coefficients $(u_i')_{i=0}^{N_{V'}}$:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{ccccc}\n",
    "  \\phi_0' & \\phi_1' &  &  & \\\\\n",
    "  & \\phi_1' & \\phi_2' &  & \\\\\n",
    "  &  & \\phi_2' & \\phi_3' & \\\\\n",
    "  &  &  & \\phi_3' & \\phi_4'\n",
    "\\end{array}\\right)  \\left(\\begin{array}{c}\n",
    "  u_0\\\\\n",
    "  u_1\\\\\n",
    "  u_2\\\\\n",
    "  u_3\\\\\n",
    "  u_4\n",
    "\\end{array}\\right) = \\left(\\begin{array}{c}\n",
    "  u_0'\\\\\n",
    "  u_1'\\\\\n",
    "  u_2'\\\\\n",
    "  u_3'\n",
    "\\end{array}\\right).$$\n",
    "\n",
    "Note that in this particular instance and with the assumptions made, we obtain a band matrix and computing $u'$ is actually a matter of computing the dot product of a \"subset\" of the vector of constants $(\\phi_0', ..., \\phi_{N_{V'}}')$ with $u$.\n",
    "\n",
    "However in other situations, e.g. in higher dimensions, the ordering of the nodes won't be as convenient. We proceed then more generally as follows: Let $i$ run over all cell indices and let $\\iota_i$ be the local-to-global mappings for $V$ and $\\iota_i'$ for $V'$. Initialise the matrix $M$ of the discrete gradient to zero. At each step of the construction of $M$ we edit row $r = \\iota_i'(0)$, i.e. the row whose product by $(u)_j$ will return the coefficient for the dof in $V'$ corresponding to cell $i$.\n",
    "\n",
    "Now, for every vertex $v_j,\\ j \\in \\{0,...,d\\}$ in cell $i$ compute the value of the derivative of the global dof $\\phi_{\\iota_r(j)}$ and set\n",
    "\n",
    "$$M_{r j} = \\phi_{\\iota_r(j)},\\ j \\in \\{0,...,d\\}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrete_gradient_operator_dense(V, Vp):\n",
    "    \"\"\" Build dense matrix of the discrete gradient\n",
    "    operator between V and Vp.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1.\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dh: np.ndarray of shape (Vp.dim(), V.dim()) such that,\n",
    "            for u in V:\n",
    "        \n",
    "                np.dot(Dh, u.vector().array())\n",
    "              \n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"\n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'CG1', \"Need a CG1 source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x DG0' % gdim or\\\n",
    "           Vp.ufl_element().shortstr()[:3] == 'DG0',\\\n",
    "           \"I need a DG0 (Vector)FunctionSpace of the right number of components\"\n",
    "    assert Vp.mesh().num_cells() * gdim == Vp.dim(),\\\n",
    "           \"FunctionSpace dimensions don't match.\"\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Meshes don't match\"\n",
    "\n",
    "    dm = V.dofmap()\n",
    "    dmp = Vp.dofmap()\n",
    "    e = V.element()\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "    coordsp = Vp.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "\n",
    "    Dh = np.zeros((Vp.dim(), V.dim()))\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "    vals = np.zeros(dm.num_element_dofs(0)*gdim)\n",
    "    for cell_id in range(Vp.mesh().num_cells()):\n",
    "        rows = dmp.cell_dofs(cell_id)\n",
    "        columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[columns,:]\n",
    "        point = dof_coords[0] # Any point in the (closure of the) cell will do.\n",
    "        e.evaluate_basis_derivatives_all(1, vals, point, dof_coords, 1)\n",
    "        #print(\"rows=%s, columns=%s, point=%s, dof_coords=%s, vals=%s\" %\n",
    "        #     (rows, columns, point, dof_coords, vals.round(2)))\n",
    "        # Reshape [df_1/dx, df_1/dy, df_2/dx, df_2/dy, ...] into\n",
    "        # [[df_1/dx, df_2/dx, ...],[df_1/dy, df_2/dy, ...]] :\n",
    "        #Dh[FIXTHIS:\"rows, columns\"] = vals.reshape((-1, gdim)).T.copy()\n",
    "        for offset in range(gdim):\n",
    "            Dh[rows[offset], columns] = vals[offset::gdim].copy()\n",
    "\n",
    "    return Dh\n",
    "\n",
    "def compute_discrete_gradient_dense(V, Vp, u):\n",
    "    \"\"\" Returns the discrete gradient of u.\n",
    "    NOTE: this implementation uses dense matrices internally.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1. (redundant...)\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A Function in Vp interpolating the gradient of u.\n",
    "    \"\"\"\n",
    "\n",
    "    Dh = discrete_gradient_operator_dense(V, Vp)\n",
    "    up = Function(Vp)\n",
    "    up.vector().set_local(np.dot(Dh, u.vector().array()))\n",
    "    up.vector().apply('insert')\n",
    "\n",
    "    return up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the previous code we start with an expression whose derivative we can compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT, RIGHT = -pi, 2*pi\n",
    "mesh = IntervalMesh(100, LEFT, RIGHT)\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "Vp = FunctionSpace(mesh, \"DG\", 0)\n",
    "\n",
    "#x = SpatialCoordinate(mesh)\n",
    "#f = sin(x[0])\n",
    "#u = project(f, V)\n",
    "u = interpolate(Expression(\"sin(x[0])\", element=V.ufl_element()), V)\n",
    "dg_u = compute_discrete_gradient_dense(V, Vp, u)\n",
    "\n",
    "# Test\n",
    "#up = project(f.dx(0), Vp)\n",
    "up = interpolate(Expression(\"cos(x[0])\", element=Vp.ufl_element()), Vp)\n",
    "print(\"Error: %e\" % (dg_u.vector() - up.vector()).norm('linf'))\n",
    "plot(up)\n",
    "plot(dg_u)\n",
    "_ = pl.xlim((LEFT*1.1, RIGHT*1.1)), pl.ylim((-1.1,1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A detour using projections\n",
    "\n",
    "The following method computes the solution via a projection onto DG0 but instead of letting FEniCS assemble the mass matrix, we make use of the fact that it is diagonal with entries given by the cell volume. Then it is trivial to invert it and multiply the rhs of the projection problem. The idea and code are taken from [this question on FEniCS Q&A](https://fenicsproject.org/qa/12634/gradient-of-a-cg-order-one-element?show=12646#a12646)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh = UnitCubeMesh(10, 10, 10)\n",
    "W = FunctionSpace(mesh, 'CG', 1)\n",
    "Q = VectorFunctionSpace(mesh, 'DG', 0)\n",
    "p, q = TrialFunction(Q), TestFunction(Q)\n",
    "\n",
    "f = Function(W)\n",
    "f_vec = f.vector()\n",
    "f_vec.set_local(np.random.rand(f_vec.local_size()))\n",
    "f_vec.apply('insert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the gradient via a projection. **NOTE** that the computation for the form $L$ will have to interpolate $f$, which is in \"W\", into the space $T$ where the test function $q$ lives in order to compute the integral. [WHY?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "L = inner(grad(f), q)*dx\n",
    "M = assemble(inner(p, q)*dx)\n",
    "b = assemble(L)\n",
    "\n",
    "grad_f0 = Function(Q)\n",
    "x0 = grad_f0.vector()\n",
    "_ = solve(M, x0, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiroK's idea (which amounts to building our matrix $D_h$) in the forum is to \"assemble the action of Minv onto the rhs - no mass matrix needed\". The improvement in speed is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MinvL = (1/CellVolume(Q.mesh()))*inner(grad(f), q)*dx\n",
    "x = assemble(MinvL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_f = Function(Q, x)\n",
    "print(\"Error: %e\" % (x - x0).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the first approach we compute $M$, then solve $M x = b$ and in the second we compute $M^{-1}$ directly to obtain $x = M^{-1} b$.\n",
    "\n",
    "### How does the assembly of the projection problem work?\n",
    "\n",
    "Write the compiled form to a file and check `dgrad_cell_integral_0_otherwise::tabulate_tensor()` for the implementation. Recall that `u.dx()` in the form is the derivative of a terminal node in UFL so it is the responsibility of FFC to fill that. How does this work again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ffc\n",
    "with open(\"/tmp/dgrad.h\", \"wt\") as fd:\n",
    "    out = ffc.compile_form(MinvL, prefix=\"dgrad\")\n",
    "    fd.write(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And back\n",
    "\n",
    "We can use our function instead. This will be much slower and also use a lot of memory because of the dense matrix we are using. The error is different, though. **Could this be significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dg_f = compute_discrete_gradient_dense(W, Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (dg_f.vector() - grad_f0.vector()).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the PETSc backend\n",
    "\n",
    "By using PETSc We can achieve a (back-of-the-napkin) speed improvement of up to 50 times wrt. the implementation with dense matrices and stay in the same range of running times than `project()`. We can only test for manageable matrix sizes but we can now of course handle bigger matrices. The speedup depends greatly on the size of the matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrete_gradient_operator(V, Vp):\n",
    "    \"\"\" Build sparse PETSc matrix of the discrete gradient\n",
    "    operator between V and Vp.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1.\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dh: PETSc sparse matrix such that for u in V,\n",
    "              Dh * u.vector().array()\n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"   \n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'CG1',\\\n",
    "           \"Need a CG1 source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x DG0' % gdim or\\\n",
    "           Vp.ufl_element().shortstr()[:3] == 'DG0',\\\n",
    "           \"I need a DG0 (Vector)FunctionSpace of the right number of components\"\n",
    "    assert Vp.mesh().num_cells() * gdim == Vp.dim(),\\\n",
    "           \"FunctionSpace dimensions don't match\"\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Number of cells in the meshes don't match\"\n",
    "\n",
    "    dm = V.dofmap()\n",
    "    dmp = Vp.dofmap()\n",
    "    e = V.element()\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "    coordsp = Vp.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "\n",
    "    Dh = PETSc.Mat()\n",
    "    Dh.create(PETSc.COMM_WORLD)  # What is this?\n",
    "    Dh.setSizes([Vp.dim(), V.dim()])\n",
    "    Dh.setType(\"aij\")\n",
    "    Dh.setUp()\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "    vals = np.zeros(dm.num_element_dofs(0)*gdim)\n",
    "    # TODO: check this for parallel operation...\n",
    "    istart, iend = Dh.getOwnershipRange()\n",
    "    print (\"This process owns the range %d - %d\" % (istart, iend))\n",
    "    for cell_id in range(Vp.mesh().num_cells()):\n",
    "        rows = dmp.cell_dofs(cell_id)\n",
    "        rows = rows[(rows>=istart) & (rows < iend)]\n",
    "        columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[columns,:]\n",
    "        point = dof_coords[0] # Any point in the (closure of the) cell will do.\n",
    "        e.evaluate_basis_derivatives_all(1, vals, point, dof_coords, 1)\n",
    "        #print(\"rows=%s, columns=%s, point=%s, dof_coords=%s, vals=%s\" %\n",
    "        #     (rows, columns, point, dof_coords, vals.round(2)))\n",
    "        # Reshape [df_1/dx, df_1/dy, df_2/dx, df_2/dy, ...] into\n",
    "        # [[df_1/dx, df_2/dx, ...],[df_1/dy, df_2/dy, ...]] :\n",
    "        # NOTE: the copy() is necessary!\n",
    "        Dh.setValues(rows, columns, vals.reshape((-1, gdim)).T.copy())\n",
    "    Dh.assemble()\n",
    "    return Dh\n",
    "\n",
    "def compute_discrete_gradient(V, Vp, u):\n",
    "    \"\"\" Returns the discrete gradient of u.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1. (redundant...)\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A Function in Vp interpolating the gradient of u.\n",
    "    \"\"\"\n",
    "    Dh = discrete_gradient_operator(V, Vp)\n",
    "    du = Function(Vp)\n",
    "    petsc_u = as_backend_type(u.vector()).vec()\n",
    "    petsc_du = as_backend_type(du.vector()).vec()\n",
    "    \n",
    "    Dh.mult(petsc_u, petsc_du)\n",
    "    du.vector().apply('insert')\n",
    "\n",
    "    return du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instruct FFC to produce the code for evaluate_basis_derivatives()\n",
    "parameters[\"form_compiler\"][\"no-evaluate_basis_derivatives\"] = False\n",
    "\n",
    "LEFT, RIGHT = -pi, 2*pi\n",
    "mesh = IntervalMesh(1000, LEFT, RIGHT)\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "Vp = FunctionSpace(mesh, \"DG\", 0)\n",
    "\n",
    "#Dh = discrete_gradient_operator(V, Vp)\n",
    "u = interpolate(Expression(\"sin(x[0])\", degree=1), V)\n",
    "du0 = interpolate(Expression(\"cos(x[0])\", degree=0), Vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "du = compute_discrete_gradient(V, Vp, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (du.vector() - du0.vector()).norm('linf'))\n",
    "_ = plot(du)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is faster than the solution with dense matrices but obviously still much slower (a little below 40 times) than building $M^{-1}$ directly because of the hideously slow python loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dgrad_f = compute_discrete_gradient(W, Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (dgrad_f.vector() - grad_f0.vector()).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete gradient for DKT\n",
    "\n",
    "Implementation of\n",
    "\n",
    "$$\\nabla_h:W_h \\rightarrow \\Theta_h$$\n",
    "\n",
    "for Functions over the whole space. Recall that the operator $\\nabla_h$ is given cell-wise by the matrix\n",
    "\n",
    "$$M = .$$\n",
    "\n",
    "Since most of it won't change, we compute it in two steps: an initialization step, which sets the fixed entries and a per-cell step, where we set the entries for each cell. **Note:** because this is just a hack, we use temporaries, hence the need to encapsulate everything in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DKTCellGradient(object):\n",
    "    \"\"\" Computes the transformation matrix for $\\nabla_h$ over one cell.\n",
    "    \n",
    "    This assumes that the dofs of the \"source\" cell (in DKT) are ordered as\n",
    "    \n",
    "         w1, w1_x, w1_y, w2, w2_x, w2_y, w3, w3_x, w3_y,\n",
    "         \n",
    "    i.e. point evaluation, partial derivatives for each vertex in turn, and\n",
    "    those of the \"target\" cell (in P_2^2) as\n",
    "    \n",
    "        t1_0, t1_1, t2_0, t2_1, t3_0, t3_1, ts1_0, ts1_1, ts2_0, ts2_1, ts3_0, ts3_1\n",
    "        \n",
    "    i.e. values at the three vertices, then values at the the midpoints of the\n",
    "    opposite sides.\n",
    "    \"\"\"\n",
    "    def __init__(self, m:int, n:int):\n",
    "        \"\"\" Initialize the matrix with m rows (target's local space_dimension())\n",
    "        and n columns (source's local space_dimension().\"\"\"\n",
    "        self.M = np.zeros((m, n), dtype=np.float)\n",
    "        rows = [[0,1], [2,3], [4,5], [6,7], [8,9], [10,11]]\n",
    "        # Hack to make fancy indexing with lists work:\n",
    "        # if one of rows[i], self.cols[j] has shape 2,1, broadcasting will actually\n",
    "        # compute the outer product of rows[i] and cols[j], instead of a \"zip\"\n",
    "        # of sorts.\n",
    "        self.rows = list(map(lambda x: np.array(x).reshape(2,1), rows))\n",
    "        self.cols = [0, [1,2], 3, [4,5], 6, [7,8]]\n",
    "        #self.cols = list(map(lambda x: np.array(x).reshape((-1,1)), self.cols))\n",
    "        # TODO: Note that storing these copies of the identity is silly\n",
    "        # When we apply the operator, it would make more sense to just copy\n",
    "        # the partial derivative dofs (which is what these first 3 multiplications \n",
    "        # with the identity do), then multiply with the lower part of M...\n",
    "        # (But we still need these here if we insist on building a global matrix\n",
    "        # which acts on all dofs of the space simultaneously)\n",
    "        self.M[self.rows[0], self.cols[1]] = np.eye(2)\n",
    "        self.M[self.rows[1], self.cols[3]] = np.eye(2)\n",
    "        self.M[self.rows[2], self.cols[5]] = np.eye(2)\n",
    "\n",
    "        # We are only defined for triangles (to do: assert this)\n",
    "        # tdim = 2, num_vertices = 3\n",
    "\n",
    "        # Init temporaries\n",
    "        self.tt = np.empty((3, 2))\n",
    "        self.TT = np.empty((3, 2, 2))\n",
    "        self.ss = np.empty(3)\n",
    "\n",
    "    def update(self, cell:Cell):\n",
    "        \"\"\"Update the mutating entries of M for the given cell.\"\"\"\n",
    "        cc = cell.get_vertex_coordinates().reshape(-1, 2)\n",
    "        self.tt[0] = (cc[2] - cc[1])\n",
    "        self.tt[1] = -(cc[0] - cc[2])  # Magic: why was this minus sign here again?\n",
    "        self.tt[2] = (cc[1] - cc[0])\n",
    "        for i in range(3):\n",
    "            self.ss[i] = np.linalg.norm(self.tt[i], ord=2)\n",
    "            self.tt[i] /= self.ss[i]\n",
    "            self.TT[i] = -3./4 * np.outer(self.tt[i], self.tt[i])\n",
    "            # HERE! if we don't use the hierarchical basis we need to add this, see...\n",
    "            self.TT[i] += 0.5*np.eye(2)\n",
    "            self.tt[i] *= -3./(2*self.ss[i])\n",
    "\n",
    "        self.M[self.rows[3], self.cols[2]] = self.tt[0].copy().reshape(2,1)\n",
    "        self.M[self.rows[3], self.cols[3]] = self.TT[0].copy()\n",
    "        self.M[self.rows[3], self.cols[4]] = -self.tt[0].copy().reshape(2,1)\n",
    "        self.M[self.rows[3], self.cols[5]] = self.TT[0].copy()\n",
    "\n",
    "        self.M[self.rows[4], self.cols[0]] = self.tt[1].copy().reshape(2,1)\n",
    "        self.M[self.rows[4], self.cols[1]] = self.TT[1].copy()\n",
    "        self.M[self.rows[4], self.cols[4]] = -self.tt[1].copy().reshape(2,1)\n",
    "        self.M[self.rows[4], self.cols[5]] = self.TT[1].copy()\n",
    "\n",
    "        self.M[self.rows[5], self.cols[0]] = self.tt[2].copy().reshape(2,1)\n",
    "        self.M[self.rows[5], self.cols[1]] = self.TT[2].copy()\n",
    "        self.M[self.rows[5], self.cols[2]] = -self.tt[2].copy().reshape(2,1)\n",
    "        self.M[self.rows[5], self.cols[3]] = self.TT[2].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now aggregate the previous cell-wise operator into one acting over discrete functions over the whole space.\n",
    "\n",
    "**Fixme:** this is very inefficient:\n",
    "\n",
    "* There is no need to create and multiply by the first 6 rows of the cell matrix. If we didn't create a \"global matrix\", i.e. acting on whole vectors of coefficients, but instead proceeded cell by cell this would be faster (albeit at the cost of a python loop, which might prove to be even worse)\n",
    "* If I keep the whole matrix, I should at least try to preinit the sparsity pattern.\n",
    "* It should be possible to loop through all facets instead of cells. This should reduce computing time because of the fewer updates to the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     43
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dkt_gradient_operator(V, Vp):\n",
    "    \"\"\" Build sparse PETSc matrix of the discrete gradient\n",
    "    operator between V and Vp.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type DKT.\n",
    "        Vp: Target (Vector)FunctionSpace of type P2\n",
    "            (WITHOUT a hierarchical basis)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dh: PETSc sparse matrix such that for u in V,\n",
    "              Dh * u.vector().array()\n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"   \n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'DKT',\\\n",
    "           \"I need a DKT source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x CG2' % gdim,\\\n",
    "           \"I need a CG2 VectorFunctionSpace with %d components\" % gdim\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Number of cells in the meshes don't match\"\n",
    "    dm = V.dofmap()\n",
    "    dmp1, dmp2 = Vp.sub(0).dofmap(), Vp.sub(1).dofmap()\n",
    "    e = V.element()\n",
    "    ep = Vp.element()\n",
    "    tdim = e.topological_dimension()\n",
    "    assert tdim == 2, \"I need topological dimension 2 (was %d)\" % tdim\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, tdim))\n",
    "\n",
    "    Dh = PETSc.Mat()\n",
    "    Dh.create(PETSc.COMM_WORLD)\n",
    "    Dh.setSizes([Vp.dim(), V.dim()])\n",
    "    Dh.setType(\"aij\")\n",
    "    Dh.setUp()\n",
    "    # In order not to assume the following it would be enough\n",
    "    # to create the array inside the loop...\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "\n",
    "    ## Preinit element-wise gradient\n",
    "    grad = DKTCellGradient(ep.space_dimension(), e.space_dimension())\n",
    "\n",
    "    # TODO: check this for parallel operation...\n",
    "    istart, iend = Dh.getOwnershipRange()\n",
    "    #print (\"This process owns the range %d - %d\" % (istart, iend))\n",
    "\n",
    "    visited = set()\n",
    "    # Wait, this could be ok\n",
    "    #print(\"##########################################\")\n",
    "    #print(\"#FIXME!!!! dest_rows is completely WRONG!#\")\n",
    "    #print(\"##########################################\")\n",
    "    \n",
    "    for cell_id in range(V.mesh().num_cells()):\n",
    "        cell = Cell(V.mesh(), cell_id)\n",
    "        facets = cell.entities(2)\n",
    "        grad.update(cell)\n",
    "        # Massage dofs into the ordering we require with\n",
    "        # both coordinates for each vector-valued dof consecutive.\n",
    "        dest_rows = np.array(list(chain.from_iterable(zip(dmp1.cell_dofs(cell_id),\n",
    "                                                          dmp2.cell_dofs(cell_id)))),\n",
    "                             dtype=np.intc)\n",
    "        dest_rows = dest_rows[(dest_rows>=istart) & (dest_rows < iend)]\n",
    "        # dofs in V are already in the proper ordering (point eval, gradient eval, ...)\n",
    "        dest_columns = dm.cell_dofs(cell_id)\n",
    "\n",
    "        # NOTE: the copy() is necessary!\n",
    "        #print(\"Setting:\\n\\trows=%s\\n\\tcols=%s\\nwith:\\n%s\" % (dest_rows, dest_columns, M))\n",
    "        Dh.setValues(dest_rows, dest_columns, grad.M.copy())\n",
    "        assert len(dest_rows)*len(dest_columns) ==  grad.M.size, \"duh\"\n",
    "    Dh.assemble()\n",
    "    return Dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_dkt_gradient(V, Vp, u):\n",
    "    \"\"\" Returns the discrete gradient of u.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type DKT. (redundant...)\n",
    "        Vp: Target VectorFunctionSpace of type CG2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A Function in Vp interpolating the gradient of u.\n",
    "    \"\"\"\n",
    "    Dh = dkt_gradient_operator(V, Vp)\n",
    "    du = Function(Vp)\n",
    "    petsc_u = as_backend_type(u.vector()).vec()\n",
    "    petsc_du = as_backend_type(du.vector()).vec()\n",
    "    \n",
    "    Dh.mult(petsc_u, petsc_du)\n",
    "    du.vector().apply('insert')\n",
    "\n",
    "    return du"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from interpolation import interpolate_hermite\n",
    "import mshr\n",
    "\n",
    "domain = mshr.Rectangle(Point(1.0, 1.0), Point(2.0, 2.0))\n",
    "mesh = mshr.generate_mesh(domain, 10)\n",
    "W = FunctionSpace(mesh, 'DKT', 3)\n",
    "T = VectorFunctionSpace(mesh, 'Lagrange', 2, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit  #(~24ms)\n",
    "\n",
    "#  Shapes do not match: <Argument ...> and <Grad ...>.??!?\n",
    "class Fun(Expression):\n",
    "    def eval(self, value, x):\n",
    "        value = x[0]*x[1]\n",
    "    def value_shape(self):\n",
    "        return (2,)\n",
    "#f = Fun(degree=3, domain=mesh)\n",
    "f = Expression(\"2*x[0]*x[0]*x[1]/sqrt(x[1])\", degree=3, domain=mesh)\n",
    "gf = project(grad(f), T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit  #(~237ms)\n",
    "from utils import make_derivatives\n",
    "import autograd.numpy as np\n",
    "@make_derivatives\n",
    "def fun(x,y):\n",
    "    return 2*x**2*y/np.sqrt(y)\n",
    "\n",
    "w = interpolate_hermite(fun, W)\n",
    "dgf = compute_dkt_gradient(W, T, w)\n",
    "_ = plot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not np.allclose(gf.vector().array(), dgf.vector().array(), atol=1e-11):\n",
    "    dgfa, gfa = dgf.vector().array(), gf.vector().array()\n",
    "    difs = np.abs(dgfa-gfa)/np.maximum(np.abs(dgfa), np.abs(gfa))\n",
    "    print(\"Results differ. Maximum difference = %.3e, mean relative difference = %.3e, std dev = %.3e\" \n",
    "          % (np.max(np.abs(dgfa-gfa)), difs.mean(), difs.std()))\n",
    "    pl.figure(figsize=(20,10))\n",
    "    pl.subplot(1,2,1)\n",
    "    plot(mesh, alpha=0.3)\n",
    "    plot(gf)\n",
    "    pl.title(\"Projection (%.1e)\" % np.max(np.abs(gfa)))\n",
    "    pl.subplot(1,2,2)\n",
    "    plot(mesh, alpha=0.3)\n",
    "    plot(dgf)\n",
    "    _ = pl.title(\"Discrete operator (%.1e)\" % np.max(np.abs(gfa)))\n",
    "else:\n",
    "    print(\"The gradients agree!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how values at the vertices seem to be correct, yet there is still a difference. Indeed the issue seems to be mostly at the facet dofs. First let's extract bith vertex and facet dofs for each subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dofs import plot_dofs, extract_dofs_with_mask\n",
    "\n",
    "vertex_dofs_0 = extract_dofs_with_mask(T, [0,1,2])   # T.sub(0)\n",
    "vertex_dofs_1 = extract_dofs_with_mask(T, [6,7,8])   # T.sub(1)\n",
    "facet_dofs_0 = extract_dofs_with_mask(T, [3,4,5])    # T.sub(0)\n",
    "facet_dofs_1 = extract_dofs_with_mask(T, [9,10,11])  # T.sub(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following routine will do the plotting of the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_field_at_dofs(f:Function, dofs0:list, dofs1:list, **kwargs):\n",
    "    \"\"\" Plots a 2d field over a 2d domain.\n",
    "    Arguments\n",
    "    ---------\n",
    "        f: must be defined over a VectorFunctionSpace of dimension 2\n",
    "        dofs0, dofs1: dofs for the first and second components of f\n",
    "    \"\"\"\n",
    "    assert f.geometric_dimension() == 2, \"Need a 2d vector valued function\"\n",
    "    V = f.function_space()\n",
    "    assert V.element().topological_dimension() == 2, \"Need a 2d domain\"\n",
    "    \n",
    "    all_coords = V.tabulate_dof_coordinates().reshape(-1,2)\n",
    "    vf = f.vector().array()\n",
    "    coords = all_coords[dofs0]\n",
    "    assert np.all(coords == all_coords[dofs1])  # sanity check\n",
    "    pl.quiver(coords[:,0], coords[:,1], vf[dofs0], vf[dofs1], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute the list of dofs where the projected gradient and the one computed by the discrete operator disagree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bad_dofs(f:Function, g:Function, dofs0, dofs1, plot=True):\n",
    "    \"\"\"\n",
    "    f,g: Functions over the same VectorFunctionSpace V of dim=2\n",
    "    dofs0, dofs1 are dofs in V.sub(0), V.sub(1), i.e. they should be of same length and go in pairs\"\"\"\n",
    "    assert f.geometric_dimension() == g.geometric_dimension() == 2, \"Need 2d vector valued functions\"\n",
    "    assert f.function_space().element().topological_dimension() == 2, \"Need a 2d domain\"\n",
    "    vf = gf.vector().array()\n",
    "    vg = dgf.vector().array()\n",
    "    assert len(dofs0) == len(dofs1)\n",
    "    num_dofs = len(dofs0)\n",
    "    bad_dofs = []\n",
    "    for i,j in zip(dofs0, dofs1): # range(num_vertices):\n",
    "        try:\n",
    "            dx, dy = vg[i] / vf[i], vg[j] / vf[j]\n",
    "            if not (near(dx, 0, eps=1e-6) or near(dx, 1, eps=1e-6)) or\\\n",
    "               not (near(dy, 0, eps=1e-6), near(dy, 1, eps=1e-6)):\n",
    "                #print(\"Not colinear with factors = {},{}\".format(dx, dy))\n",
    "                bad_dofs.append(i)\n",
    "        except Exception as e:\n",
    "            print(\"{} Skipping {}\".format(e, i))\n",
    "    print(\"Computed gradients differ at %.2f%% of the dofs.\" % \n",
    "          (100*len(bad_dofs)/num_dofs))\n",
    "    if plot:\n",
    "        plot_dofs(T, bad_dofs, s=60, c='red', alpha=0.6)\n",
    "        plot_field_at_dofs(f, dofs0, dofs1, alpha=0.7, color='orange')\n",
    "        plot_field_at_dofs(g, dofs0, dofs1, alpha=0.8, color='green')\n",
    "    else:\n",
    "        return bad_dofs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are two nice plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(24,12))\n",
    "pl.subplot(1,2,1)\n",
    "bad_dofs(gf, dgf, vertex_dofs_0, vertex_dofs_1)\n",
    "pl.title(\"Vertex dofs (%.1e)\" % np.mean(np.abs(dgf.vector().array())))\n",
    "pl.subplot(1,2,2)\n",
    "bad_dofs(gf, dgf, facet_dofs_0, facet_dofs_1)\n",
    "_ = pl.title(\"Facet dofs (%.1e)\" % np.mean(np.abs(dgf.vector().array())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are basically ok, up to minor numerical errors (which **may build up!**, so I should be careful here...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = UnitSquareMesh(1,1)\n",
    "W = FunctionSpace(mesh, 'DKT', 3)\n",
    "T = VectorFunctionSpace(mesh, 'Lagrange', 2, dim=2)\n",
    "\n",
    "w = Function(W)\n",
    "dmw = W.dofmap()\n",
    "wdofs_cell0 = dmw.cell_dofs(0)\n",
    "wdofs_cell1 = dmw.cell_dofs(1)\n",
    "new_vals = np.zeros_like(w.vector().array())\n",
    "new_vals[wdofs_cell0] = [2,1,1,2,1,1,2,1,1]\n",
    "w.vector().set_local(new_vals)\n",
    "\n",
    "\n",
    "Dh = DKTCellGradient(T.element().space_dimension(), W.element().space_dimension())\n",
    "Dh.update(Cell(W.mesh(), 0))\n",
    "product = Dh.M@w.vector().array()[wdofs_cell0]\n",
    "\n",
    "dw2 = Function(T)\n",
    "dm0 = T.sub(0).dofmap()\n",
    "dm1 = T.sub(1).dofmap()\n",
    "tdofs0_cell0 = dm0.cell_dofs(0)\n",
    "tdofs1_cell0 = dm1.cell_dofs(0)\n",
    "#### <strike>DON'T FIXME!!!! this is NOT WRONG:</strike>\n",
    "dest_rows = np.array(list(chain.from_iterable(zip(tdofs0_cell0,tdofs1_cell0))), dtype=np.intc)\n",
    "print(tdofs0_cell0, tdofs1_cell0)\n",
    "print(dest_rows)\n",
    "#### found manually:\n",
    "dest_rows = [ 2, 3, 12, 13, 4, 5, 14, 15, 6, 7, 16, 17]\n",
    "new_vals2 = np.zeros_like(dw2.vector().array())\n",
    "new_vals2[dest_rows] = product\n",
    "dw2.vector().set_local(new_vals2)\n",
    "print(product)\n",
    "print(Dh.M)\n",
    "\n",
    "pl.figure(figsize=(12,6))\n",
    "plot(T.mesh(), alpha=0.3)\n",
    "vertex_dofs_0 = extract_dofs_with_mask(T, [0,1,2])   # T.sub(0)\n",
    "vertex_dofs_1 = extract_dofs_with_mask(T, [6,7,8])   # T.sub(1)\n",
    "facet_dofs_0 = extract_dofs_with_mask(T, [3,4,5])    # T.sub(0)\n",
    "facet_dofs_1 = extract_dofs_with_mask(T, [9,10,11])  # T.sub(1)\n",
    "plot_field_at_dofs(dw2, vertex_dofs_0, vertex_dofs_1, color='orange')\n",
    "plot_field_at_dofs(dw2, facet_dofs_0, facet_dofs_1, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over facets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dofs import facets_dofmap\n",
    "\n",
    "dm = facets_dofmap(T)\n",
    "dm.facet_dofs[12]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "167px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "1247px",
    "left": "0px",
    "right": "1601px",
    "top": "84px",
    "width": "368px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
