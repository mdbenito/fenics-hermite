{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete gradient operators\n",
    "\n",
    "This notebook collects my progress towards the definition of the operator\n",
    "\n",
    "$$\\nabla_h:W_h \\rightarrow \\Theta_h$$\n",
    "\n",
    "as defined in (Bartels, 2015) ยง8.2.1.\n",
    "\n",
    "## First goal: derivative of a piecewise linear function\n",
    "\n",
    "** To do for this goal:** A rewrite in C++?\n",
    "\n",
    "Let $u \\in V$, where $V$ is a CG1 finite element space. Then $u'$ is piecewise constant (i.e. it is in DG0). We want to compute the matrix $D_h$ for \n",
    "\n",
    "$$\\nabla_h:V \\rightarrow V'$$\n",
    "\n",
    "such that $(D_h u)_j$ = $(\\nabla_h u)_j = u_j'$. Note that we are using the same  notation for a function $u$ and for the vector of its coefficients in the basis of the space it lives on.\n",
    "\n",
    "Since $u'$ is not in the same space as $u$, in FEniCS we need to `project()` it onto $V'$, which is costly. What we are doing is to manually compute the derivative. This should be easy since\n",
    "\n",
    "$$ u = \\sum_i \\alpha_i \\phi_i $$\n",
    "\n",
    "where $V = \\text{span} \\{\\phi_i\\} $, hence:\n",
    "\n",
    "$$ u' = \\sum_i \\alpha_i \\phi_i'. $$\n",
    "\n",
    "We can use `evaluate_basis_derivatives()` for this purpose, assembling the transformation matrix by hand.\n",
    "\n",
    "We define $V' = \\text{span} \\{\\phi_i'\\}$, a DG0 space, and compute the linear mapping of dofs from $V$ to $V'$, then apply this mapping to the coefficients of $u$ and construct $u' \\in V'$ with these coefficients.\n",
    "\n",
    "For simplicity, consider first a 1D mesh. Let $i \\in \\{0,1,...,M\\}$ be an index over the cells of the mesh such that:\n",
    "\n",
    "* $u_i,u_{i+1}$ are the coefficients for the dofs in $V$ over cell $i$\n",
    "* $u_i'$ is the coefficient for the only dof in $V'$ (the constant 1) over cell $i$\n",
    "\n",
    "Then we only need to compute $\\phi_i'$ for each $i$ to obtain the new vector of coefficients $(u_i')_{i=0}^{N_{V'}}$:\n",
    "\n",
    "$$\n",
    "\\left(\\begin{array}{ccccc}\n",
    "  \\phi_0' & \\phi_1' &  &  & \\\\\n",
    "  & \\phi_1' & \\phi_2' &  & \\\\\n",
    "  &  & \\phi_2' & \\phi_3' & \\\\\n",
    "  &  &  & \\phi_3' & \\phi_4'\n",
    "\\end{array}\\right)  \\left(\\begin{array}{c}\n",
    "  u_0\\\\\n",
    "  u_1\\\\\n",
    "  u_2\\\\\n",
    "  u_3\\\\\n",
    "  u_4\n",
    "\\end{array}\\right) = \\left(\\begin{array}{c}\n",
    "  u_0'\\\\\n",
    "  u_1'\\\\\n",
    "  u_2'\\\\\n",
    "  u_3'\n",
    "\\end{array}\\right).$$\n",
    "\n",
    "Note that in this particular instance and with the assumptions made, we obtain a band matrix and computing $u'$ is actually a matter of computing the dot product of a \"subset\" of the vector of constants $(\\phi_0', ..., \\phi_{N_{V'}}')$ with $u$.\n",
    "\n",
    "However in other situations, e.g. in higher dimensions, the ordering of the nodes won't be as convenient. We proceed then more generally as follows: Let $i$ run over all cell indices and let $\\iota_i$ be the local-to-global mappings for $V$ and $\\iota_i'$ for $V'$. Initialise the matrix $M$ of the discrete gradient to zero. At each step of the construction of $M$ we edit row $r = \\iota_i'(0)$, i.e. the row whose product by $(u)_j$ will return the coefficient for the dof in $V'$ corresponding to cell $i$.\n",
    "\n",
    "Now, for every vertex $v_j,\\ j \\in \\{0,...,d\\}$ in cell $i$ compute the value of the derivative of the global dof $\\phi_{\\iota_r(j)}$ and set\n",
    "\n",
    "$$M_{r j} = \\phi_{\\iota_r(j)},\\ j \\in \\{0,...,d\\}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from dolfin import *\n",
    "from petsc4py import PETSc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "def __nbinit__():\n",
    "    global __all__\n",
    "    __all__ = ['compute_discrete_gradient_dense', \n",
    "               'compute_discrete_gradient',\n",
    "               'compute_dkt_gradient']\n",
    "    global parameters\n",
    "    # instruct FFC to produce the code for evaluate_basis_derivatives()\n",
    "    parameters[\"form_compiler\"][\"no-evaluate_basis_derivatives\"] = False\n",
    "\n",
    "__nbinit__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discrete_gradient_operator_dense(V, Vp):\n",
    "    \"\"\" Build dense matrix of the discrete gradient\n",
    "    operator between V and Vp.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1.\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dh: np.ndarray of shape (Vp.dim(), V.dim()) such that,\n",
    "            for u in V:\n",
    "        \n",
    "                np.dot(Dh, u.vector().array())\n",
    "              \n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"\n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'CG1', \"Need a CG1 source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x DG0' % gdim or\\\n",
    "           Vp.ufl_element().shortstr()[:3] == 'DG0',\\\n",
    "           \"I need a DG0 (Vector)FunctionSpace of the right number of components\"\n",
    "    assert Vp.mesh().num_cells() * gdim == Vp.dim(),\\\n",
    "           \"FunctionSpace dimensions don't match.\"\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Meshes don't match\"\n",
    "\n",
    "    dm = V.dofmap()\n",
    "    dmp = Vp.dofmap()\n",
    "    e = V.element()\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "    coordsp = Vp.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "\n",
    "    Dh = np.zeros((Vp.dim(), V.dim()))\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "    vals = np.zeros(dm.num_element_dofs(0)*gdim)\n",
    "    for cell_id in range(Vp.mesh().num_cells()):\n",
    "        rows = dmp.cell_dofs(cell_id)\n",
    "        columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[columns,:]\n",
    "        point = dof_coords[0] # Any point in the (closure of the) cell will do.\n",
    "        e.evaluate_basis_derivatives_all(1, vals, point, dof_coords, 1)\n",
    "        #print(\"rows=%s, columns=%s, point=%s, dof_coords=%s, vals=%s\" %\n",
    "        #     (rows, columns, point, dof_coords, vals.round(2)))\n",
    "        # Reshape [df_1/dx, df_1/dy, df_2/dx, df_2/dy, ...] into\n",
    "        # [[df_1/dx, df_2/dx, ...],[df_1/dy, df_2/dy, ...]] :\n",
    "        #Dh[FIXTHIS:\"rows, columns\"] = vals.reshape((-1, gdim)).T.copy()\n",
    "        for offset in range(gdim):\n",
    "            Dh[rows[offset], columns] = vals[offset::gdim].copy()\n",
    "\n",
    "    return Dh\n",
    "\n",
    "def compute_discrete_gradient_dense(V, Vp, u):\n",
    "    \"\"\" Returns the discrete gradient of u.\n",
    "    NOTE: this implementation uses dense matrices internally.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1. (redundant...)\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A Function in Vp interpolating the gradient of u.\n",
    "    \"\"\"\n",
    "\n",
    "    Dh = discrete_gradient_operator_dense(V, Vp)\n",
    "    up = Function(Vp)\n",
    "    up.vector().set_local(np.dot(Dh, u.vector().array()))\n",
    "    up.vector().apply('insert')\n",
    "\n",
    "    return up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the previous code we start with an expression whose derivative we can compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instruct FFC to produce the code for evaluate_basis_derivatives()\n",
    "parameters[\"form_compiler\"][\"no-evaluate_basis_derivatives\"] = False\n",
    "\n",
    "LEFT, RIGHT = -pi, 2*pi\n",
    "mesh = IntervalMesh(100, LEFT, RIGHT)\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "Vp = FunctionSpace(mesh, \"DG\", 0)\n",
    "\n",
    "#x = SpatialCoordinate(mesh)\n",
    "#f = sin(x[0])\n",
    "#u = project(f, V)\n",
    "u = interpolate(Expression(\"sin(x[0])\", element=V.ufl_element()), V)\n",
    "dg_u = compute_discrete_gradient_dense(V, Vp, u)\n",
    "\n",
    "# Test\n",
    "#up = project(f.dx(0), Vp)\n",
    "up = interpolate(Expression(\"cos(x[0])\", element=Vp.ufl_element()), Vp)\n",
    "print(\"Error: %e\" % (dg_u.vector() - up.vector()).norm('linf'))\n",
    "plot(up)\n",
    "plot(dg_u)\n",
    "_ = pl.xlim((LEFT*1.1, RIGHT*1.1)), pl.ylim((-1.1,1.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A detour using projections\n",
    "\n",
    "The following method computes the solution via a projection onto DG0 but instead of letting FEniCS assemble the mass matrix, we make use of the fact that it is diagonal with entries given by the cell volume. Then it is trivial to invert it and multiply the rhs of the projection problem. The idea and code are taken from [this question on FEniCS Q&A](https://fenicsproject.org/qa/12634/gradient-of-a-cg-order-one-element?show=12646#a12646)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dolfin import *\n",
    "import numpy as np\n",
    "\n",
    "mesh = UnitCubeMesh(30, 30, 30)\n",
    "W = FunctionSpace(mesh, 'CG', 1)\n",
    "Q = VectorFunctionSpace(mesh, 'DG', 0)\n",
    "p, q = TrialFunction(Q), TestFunction(Q)\n",
    "\n",
    "f = Function(W)\n",
    "f_vec = f.vector()\n",
    "f_vec.set_local(np.random.rand(f_vec.local_size()))\n",
    "f_vec.apply('insert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first compute the gradient via a projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "L = inner(grad(f), q)*dx\n",
    "M = assemble(inner(p, q)*dx)\n",
    "b = assemble(L)\n",
    "\n",
    "grad_f0 = Function(Q)\n",
    "x0 = grad_f0.vector()\n",
    "_ = solve(M, x0, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MiroK's idea (which amounts to building our matrix $D_h$) in the forum is to \"assemble the action of Minv onto the rhs - no mass matrix needed\". The improvement in speed is huge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "MinvL = (1/CellVolume(Q.mesh()))*inner(grad(f), q)*dx\n",
    "x = assemble(MinvL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grad_f = Function(Q, x)\n",
    "print(\"Error: %e\" % (x - x0).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the first approach we compute $M$, then solve $M x = b$ and in the second we compute $M^{-1}$ directly to obtain $x = M^{-1} b$.\n",
    "\n",
    "### How does the assembly of the projection problem work?\n",
    "\n",
    "Write the compiled form to a file and check `dgrad_cell_integral_0_otherwise::tabulate_tensor()` for the implementation. Recall that `u.dx()` in the form is the derivative of a terminal node in UFL so it is the responsibility of FFC to fill that. How does this work again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ffc\n",
    "with open(\"/tmp/dgrad.h\", \"wt\") as fd:\n",
    "    out = ffc.compile_form(MinvL, prefix=\"dgrad\")\n",
    "    fd.write(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And back\n",
    "\n",
    "We can use our function instead. This will be much slower and also use a lot of memory because of the dense matrix we are using. The error is different, though. **Could this be significant?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dg_f = compute_discrete_gradient_dense(W, Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (dg_f.vector() - grad_f0.vector()).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the PETSc backend\n",
    "\n",
    "We achieve next a (back-of-the-napkin) speed improvement of up to 50 times wrt. the implementation with dense matrices and stay in the same range of running times than the method using `project()`. We can only test for manageable matrix sizes but we can now of course manage bigger matrices. The speedup depends greatly on the size of the matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discrete_gradient_operator(V, Vp):\n",
    "    \"\"\" Build sparse PETSc matrix of the discrete gradient\n",
    "    operator between V and Vp.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1.\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dh: PETSc sparse matrix such that for u in V,\n",
    "              Dh * u.vector().array()\n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"   \n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'CG1',\\\n",
    "           \"Need a CG1 source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x DG0' % gdim or\\\n",
    "           Vp.ufl_element().shortstr()[:3] == 'DG0',\\\n",
    "           \"I need a DG0 (Vector)FunctionSpace of the right number of components\"\n",
    "    assert Vp.mesh().num_cells() * gdim == Vp.dim(),\\\n",
    "           \"FunctionSpace dimensions don't match\"\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Number of cells in the meshes don't match\"\n",
    "\n",
    "    dm = V.dofmap()\n",
    "    dmp = Vp.dofmap()\n",
    "    e = V.element()\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "    coordsp = Vp.tabulate_dof_coordinates().reshape((-1, gdim))\n",
    "\n",
    "    Dh = PETSc.Mat()\n",
    "    Dh.create(PETSc.COMM_WORLD)  # What is this?\n",
    "    Dh.setSizes([Vp.dim(), V.dim()])\n",
    "    Dh.setType(\"aij\")\n",
    "    Dh.setUp()\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "    vals = np.zeros(dm.num_element_dofs(0)*gdim)\n",
    "    # TODO: check this for parallel operation...\n",
    "    istart, iend = Dh.getOwnershipRange()\n",
    "    print (\"This process owns the range %d - %d\" % (istart, iend))\n",
    "    for cell_id in range(Vp.mesh().num_cells()):\n",
    "        rows = dmp.cell_dofs(cell_id)\n",
    "        rows = rows[(rows>=istart) & (rows < iend)]\n",
    "        columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[columns,:]\n",
    "        point = dof_coords[0] # Any point in the (closure of the) cell will do.\n",
    "        e.evaluate_basis_derivatives_all(1, vals, point, dof_coords, 1)\n",
    "        #print(\"rows=%s, columns=%s, point=%s, dof_coords=%s, vals=%s\" %\n",
    "        #     (rows, columns, point, dof_coords, vals.round(2)))\n",
    "        # Reshape [df_1/dx, df_1/dy, df_2/dx, df_2/dy, ...] into\n",
    "        # [[df_1/dx, df_2/dx, ...],[df_1/dy, df_2/dy, ...]] :\n",
    "        # NOTE: the copy() is necessary!\n",
    "        Dh.setValues(rows, columns, vals.reshape((-1, gdim)).T.copy())\n",
    "    Dh.assemble()\n",
    "    return Dh\n",
    "\n",
    "def compute_discrete_gradient(V, Vp, u):\n",
    "    \"\"\" Returns the discrete gradient of u.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type CG1. (redundant...)\n",
    "        Vp: Target (Vector)FunctionSpace of type DG0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A Function in Vp interpolating the gradient of u.\n",
    "    \"\"\"\n",
    "    Dh = discrete_gradient_operator(V, Vp)\n",
    "    du = Function(Vp)\n",
    "    petsc_u = as_backend_type(u.vector()).vec()\n",
    "    petsc_du = as_backend_type(du.vector()).vec()\n",
    "    \n",
    "    Dh.mult(petsc_u, petsc_du)\n",
    "    du.vector().apply('insert')\n",
    "\n",
    "    return du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instruct FFC to produce the code for evaluate_basis_derivatives()\n",
    "parameters[\"form_compiler\"][\"no-evaluate_basis_derivatives\"] = False\n",
    "\n",
    "LEFT, RIGHT = -pi, 2*pi\n",
    "mesh = IntervalMesh(1000, LEFT, RIGHT)\n",
    "V = FunctionSpace(mesh, \"CG\", 1)\n",
    "Vp = FunctionSpace(mesh, \"DG\", 0)\n",
    "\n",
    "#Dh = discrete_gradient_operator(V, Vp)\n",
    "u = interpolate(Expression(\"sin(x[0])\", degree=1), V)\n",
    "du0 = interpolate(Expression(\"cos(x[0])\", degree=0), Vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "du = compute_discrete_gradient(V, Vp, u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (du.vector() - du0.vector()).norm('linf'))\n",
    "_ = plot(du)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is faster than the solution with dense matrices but obviously still much slower (a little below 40 times) than building $M^{-1}$ directly because of the hideously slow python loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dgrad_f = compute_discrete_gradient(W, Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Error: %e\" % (dgrad_f.vector() - grad_f0.vector()).norm('linf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DKTs\n",
    "\n",
    "Theory, stuff..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dkt_gradient_operator(V, Vp):\n",
    "    \"\"\" Build sparse PETSc matrix of the discrete gradient\n",
    "    operator between V and Vp.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type DKT.\n",
    "        Vp: Target (Vector)FunctionSpace of type P2\n",
    "            (WITHOUT a hierarchical basis)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        Dh: PETSc sparse matrix such that for u in V,\n",
    "              Dh * u.vector().array()\n",
    "            yields the vector of coefficients of the discrete\n",
    "            gradient of u in Vp.\n",
    "    \"\"\"   \n",
    "    gdim = V.mesh().geometry().dim()\n",
    "    assert V.ufl_element().shortstr()[:3] == 'DKT',\\\n",
    "           \"I need a DKT source space\"\n",
    "    assert Vp.ufl_element().shortstr()[:14] == 'Vector<%d x CG2' % gdim,\\\n",
    "           \"I need a CG2 VectorFunctionSpace with %d components\" % gdim\n",
    "    assert Vp.mesh().num_cells() == V.mesh().num_cells(),\\\n",
    "           \"Number of cells in the meshes don't match\"\n",
    "    dm = V.dofmap()\n",
    "    dmp1, dmp2 = Vp.sub(0).dofmap(), Vp.sub(1).dofmap()\n",
    "    e = V.element()\n",
    "    ep = Vp.element()\n",
    "    tdim = e.topological_dimension()\n",
    "    assert tdim == 2, \"I need topological dimension 2 (was %d)\" % tdim\n",
    "    coords = V.tabulate_dof_coordinates().reshape((-1, tdim))\n",
    "\n",
    "    Dh = PETSc.Mat()\n",
    "    Dh.create(PETSc.COMM_WORLD)\n",
    "    Dh.setSizes([Vp.dim(), V.dim()])\n",
    "    Dh.setType(\"aij\")\n",
    "    Dh.setUp()\n",
    "    # In order not to assume the following it would be enough\n",
    "    # to create the array inside the loop...\n",
    "    warning(\"Assuming all cells have the same number of dofs\")\n",
    "\n",
    "    ## Preinit element-wise matrix\n",
    "    M = np.zeros((ep.space_dimension(), e.space_dimension()), dtype=np.float)\n",
    "    rows = [[0,1], [2,3], [4,5], [6,7], [8,9], [10,11]]\n",
    "    # Hack to make fancy indexing with lists work:\n",
    "    # if one of rows[i], cols[j] has shape (2,1), broadcasting will actually\n",
    "    # compute the outer product of rows[i] and cols[j], instead of a \"zip\"\n",
    "    # of sorts.\n",
    "    rows = list(map(lambda x: np.array(x).reshape((2,1)), rows))\n",
    "    cols = [0, [1,2], 3, [4,5], 6, [7,8]]\n",
    "    #cols = list(map(lambda x: np.array(x).reshape((-1,1)), cols))\n",
    "    M[rows[0],cols[1]] = np.eye(2)\n",
    "    M[rows[1],cols[3]] = np.eye(2)\n",
    "    M[rows[2],cols[5]] = np.eye(2)\n",
    "    M[rows[3],cols[1]] = -0.5*np.eye(2)\n",
    "    M[rows[4],cols[3]] = -0.5*np.eye(2)\n",
    "    M[rows[5],cols[5]] = -0.5*np.eye(2)\n",
    "\n",
    "    # Allocate temporary arrays\n",
    "    numpt = 3\n",
    "    tt = np.empty((numpt, tdim))\n",
    "    TT = np.empty((numpt, tdim, tdim))\n",
    "    ss = np.empty(numpt)\n",
    "\n",
    "    # TODO: check this for parallel operation...\n",
    "    istart, iend = Dh.getOwnershipRange()\n",
    "    print (\"This process owns the range %d - %d\" % (istart, iend))\n",
    "\n",
    "    for cell_id in range(V.mesh().num_cells()):\n",
    "        ## Compute tangents and sub-submatrices\n",
    "        c = Cell(V.mesh(), cell_id)\n",
    "        cc = c.get_vertex_coordinates().reshape((numpt, 2))\n",
    "        for i in range(numpt):\n",
    "            tt[i] = (cc[(i+1)%numpt] - cc[i%numpt])\n",
    "            ss[i] = np.linalg.norm(tt[i], ord=2)\n",
    "            tt[i] /= ss[i]\n",
    "            TT[i] = -3./4 * np.outer(tt[i], tt[i])\n",
    "            tt[i] *= -3./(2*ss[i])\n",
    "        M[rows[3], cols[2]] = tt[0].copy().reshape((2,1))\n",
    "        M[rows[3], cols[3]] = TT[0].copy()\n",
    "        M[rows[3], cols[4]] = -tt[0].copy().reshape((2,1))\n",
    "        M[rows[3], cols[5]] = TT[0].copy()\n",
    "\n",
    "        M[rows[4], cols[0]] = tt[1].copy().reshape((2,1))\n",
    "        M[rows[4], cols[1]] = TT[1].copy()\n",
    "        M[rows[4], cols[4]] = -tt[1].copy().reshape((2,1))\n",
    "        M[rows[4], cols[5]] = TT[1].copy()\n",
    "\n",
    "        M[rows[5], cols[0]] = tt[2].copy().reshape((2,1))\n",
    "        M[rows[5], cols[1]] = TT[2].copy()\n",
    "        M[rows[5], cols[2]] = -tt[2].copy().reshape((2,1))\n",
    "        M[rows[5], cols[3]] = TT[2].copy()\n",
    "\n",
    "        # Massage dofs into the ordering we require with\n",
    "        # both coordinates for each vector-valued dof consecutive.\n",
    "        dest_rows = np.array(list(chain.from_iterable(zip(dmp1.cell_dofs(cell_id),\n",
    "                                                     dmp2.cell_dofs(cell_id)))),\n",
    "                             dtype=np.intc)\n",
    "        dest_rows = dest_rows[(dest_rows>=istart) & (dest_rows < iend)]\n",
    "        # dofs in V are already in the proper ordering (point eval, gradient eval, ...)\n",
    "        dest_columns = dm.cell_dofs(cell_id)\n",
    "        dof_coords = coords[dest_columns,:]\n",
    "\n",
    "        # NOTE: the copy() is necessary!\n",
    "        #print(\"Setting:\\n\\trows=%s\\n\\tcols=%s\\nwith:\\n%s\" % (dest_rows, dest_columns, M))\n",
    "        Dh.setValues(dest_rows, dest_columns, M)\n",
    "        assert len(dest_rows)*len(dest_columns) ==  M.size, \"duh\"\n",
    "    Dh.assemble()\n",
    "    return Dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_dkt_gradient(V, Vp, u):\n",
    "    \"\"\" Returns the discrete gradient of u.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        V: Source FunctionSpace of type DKT. (redundant...)\n",
    "        Vp: Target VectorFunctionSpace of type CG2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A Function in Vp interpolating the gradient of u.\n",
    "    \"\"\"\n",
    "    Dh = dkt_gradient_operator(V, Vp)\n",
    "    du = Function(Vp)\n",
    "    petsc_u = as_backend_type(u.vector()).vec()\n",
    "    petsc_du = as_backend_type(du.vector()).vec()\n",
    "    \n",
    "    Dh.mult(petsc_u, petsc_du)\n",
    "    du.vector().apply('insert')\n",
    "\n",
    "    return du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dolfin import *\n",
    "import nbimporter\n",
    "\n",
    "W = FunctionSpace(UnitSquareMesh(1,1), 'DKT', 3)\n",
    "T = VectorFunctionSpace(W.mesh(), 'Lagrange', 2, dim=2)\n",
    "u = TrialFunction(W)\n",
    "v = TestFunction(W)\n",
    "\n",
    "Dh = dkt_gradient_operator(W, T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
